[SPOTIFIER](https://heli18.github.io/CS109_Spotifier/) |
[Introduction and EDA](https://heli18.github.io/CS109_Spotifier/intro) |
[Literature Review and Related Work](https://heli18.github.io/CS109_Spotifier/lit) |
[Models](https://heli18.github.io/CS109_Spotifier/models) |
[Results and Conclusion](https://heli18.github.io/CS109_Spotifier/results) |
[Downloads](https://heli18.github.io/CS109_Spotifier/downloads) 

# SPOTIFIER! : CS109 DATA SCIENCE FINAL PROJECT

## Introduction and EDA

### [1. Introduction and Description of Data](#introduction-and-description-of-data)
#### [a. Description of Raw and Final Data](#description-of-raw-and-final-data)
#### [b. Data Parsing](#data-parsing)
### [2. EDA](#eda)

### Introduction And Description Of Data

Playlist generation is one of the major problems in Music Recommender Systems. The idea is to generate playlists that create the best experience for users based on their preferences, taste, emotion, time of the day, etc. A successful implementation of playlist generation creates more user engagement and extends the amount of time they spent with the Spotify music application.

#### Description of Raw and Final Data

The data being used is from the Million Playlist dataset, which comprises of 1,000,000 playlists generated by Spotify users, with each playlist averaging around 67 songs.

The data is formatted in JSON with playlist properties including: name of the playlist, whether it is collaborative, number or tracks and albums it includes, duration, number of followers it has, the number of edits, and number of artists (see below). The information contained with each track property of each playlist is: artist name, track, name, album, duration of the song.

The Million Playlist dataset had more unnecessary metadata which we cleaned in the data exploration ( track_uri,artist_uri, album_uri). 


#### Data Parsing

Million Playlist dataset format:
```python
"playlists": [
	 {
		 "name": "Throwbacks",
		 "collaborative": "false",
		 "pid": 0, (remove)
		 "modified_at": 1493424000, (remove)
		 "num_tracks": 52,
		 "num_albums": 47,
		 "num_followers": 1,
		 "num_edits": 6,
		 "duration_ms": 11532414, (remove)
		 "num_artists": 37,
		 "durantion_ms_mean": ‘float’ (add)
		 "popular_artist": ‘str’ (add)
		 "popular_album": ‘str’ (add)
		 "tracks": [
			 {
				 "pos": 0, (remove)
				 "artist_name": "Missy Elliott",
				 "track_uri": "spotify:track:0UaMYEvWZi0ZqiDOoHU3YI", (remove)
				 "artist_uri": "spotify:artist:2wIVse2owClT7go1WT98tk", (remove)
				 "track_name": "Lose Control (feat. Ciara & Fat Man Scoop)",
				 "album_uri": "spotify:album:6vV5UrXcfyQD1wu4Qo2I9K", (remove)
				 "duration_ms": 226863,
				 "album_name": "The Cookbook"
		 	},
		 	...
		 ]
 	},
 	...
 ]
```

The data was combined in one dictionary and parsed using the python script below, so that the new data set has the variables we are interested in, while removing data which will not be used in further analysis.

Parsed data format:
```python
"playlists": [
	{
		"name": "Throwbacks",
		"collaborative": "false",
		"popular_album": "Departure - Recharged",
		"num_albums": 47,
		"num_tracks": 52,
		"num_followers": 1,
		"tracks": [
			{
				"artist_name": "Missy Elliott",
				"track_name": "Lose Control (feat. Ciara & Fat Man Scoop)",
				"duration_ms": 226863,
				"album_name": "The Cookbook"
			},
		]
	}
]
```

One issue that we faced was the missing data (null). So, if playlists had <= 30% of track data missing, we dropped the playlists. Since doing so would affect some of the statistics of the playlists (in our case duration of playlists), we decided to use the mean of it. 

### EDA
